/**
 * Data Analysis Agent - æ•°æ®åˆ†æ
 *
 * ç”¨äºæ•°æ®åˆ†æã€ç»Ÿè®¡è®¡ç®—ã€æ•°æ®å¯è§†åŒ–å»ºè®®ç­‰
 */

import { logger } from '../utils/logger.js';
import { promises as fs } from 'fs';
import path from 'path';
import type {
  IAgent,
  AgentConfig,
  AgentMessage,
  AgentContext,
  AgentResponse,
} from './base/Agent.js';
import { AgentCapability } from './base/Agent.js';

/**
 * Data Analysis Agent é…ç½®é€‰é¡¹
 */
export interface DataAnalysisAgentOptions {
  /** æ”¯æŒçš„æ–‡ä»¶ç±»å‹ */
  supportedFileTypes?: string[];
  /** æœ€å¤§æ–‡ä»¶å¤§å° (MB) */
  maxFileSize?: number;
}

/**
 * æ•°æ®ç»Ÿè®¡ç»“æœ
 */
interface DataStatistics {
  totalRows: number;
  totalColumns: number;
  columns: Array<{
    name: string;
    type: string;
    nullCount: number;
    uniqueCount: number;
  }>;
  summary: string;
}

/**
 * Data Analysis Agent - æ•°æ®åˆ†æ
 */
export class DataAnalysisAgent implements IAgent {
  readonly id = 'data';
  readonly name = 'Data Analysis Agent';
  readonly description = 'æ•°æ®åˆ†æï¼šç»Ÿè®¡è®¡ç®—ã€æ–‡ä»¶åˆ†æã€æ•°æ®å¯è§†åŒ–å»ºè®®';
  readonly capabilities: AgentCapability[] = [AgentCapability.Analyze, AgentCapability.Complex];
  readonly config: AgentConfig = {
    enabled: true,
    priority: 7,
    timeout: 30000,
  };

  private supportedFileTypes: string[];
  private maxFileSize: number;

  // æ•°æ®åˆ†æç›¸å…³å…³é”®è¯
  private readonly analysisKeywords = [
    // ä¸­æ–‡
    'åˆ†æ', 'ç»Ÿè®¡', 'æ•°æ®', 'è®¡ç®—', 'æ±‡æ€»', 'å¹³å‡å€¼', 'æ€»æ•°',
    'csv', 'excel', 'json', 'æ•°æ®æ–‡ä»¶', 'è¡¨æ ¼',
    // è‹±æ–‡
    'analyze', 'analysis', 'statistics', 'data', 'calculate', 'summary',
    'average', 'count', 'total', 'csv', 'excel', 'json', 'spreadsheet',
  ];

  constructor(options: DataAnalysisAgentOptions = {}) {
    this.supportedFileTypes = options.supportedFileTypes || ['.csv', '.json', '.txt', '.md'];
    this.maxFileSize = (options.maxFileSize || 10) * 1024 * 1024; // MB to bytes
    logger.info(`[DataAnalysisAgent] åˆå§‹åŒ–å®Œæˆ`);
  }

  /**
   * æ£€æŸ¥æ˜¯å¦èƒ½å¤„ç†è¯¥ä»»åŠ¡
   */
  canHandle(message: AgentMessage): number {
    const content = message.content.toLowerCase();

    // æ£€æŸ¥æ–‡ä»¶é™„ä»¶
    if (message.attachments && message.attachments.length > 0) {
      const hasDataFile = message.attachments.some(att => {
        const ext = path.extname(att.path).toLowerCase();
        return this.supportedFileTypes.includes(ext);
      });
      if (hasDataFile) return 0.9;
    }

    // å…³é”®è¯åŒ¹é…
    const hitCount = this.analysisKeywords.filter(kw => content.includes(kw)).length;
    return Math.min(hitCount * 0.12, 0.8);
  }

  /**
   * å¤„ç†æ¶ˆæ¯
   */
  async process(
    message: AgentMessage,
    context: AgentContext
  ): Promise<AgentResponse> {
    const startTime = Date.now();

    try {
      logger.info(`[DataAnalysisAgent] å¤„ç†æ¶ˆæ¯: ${message.content.substring(0, 50)}...`);

      // æ£€æŸ¥æ˜¯å¦æœ‰é™„ä»¶
      if (message.attachments && message.attachments.length > 0) {
        return await this.analyzeAttachment(message, context);
      }

      // æ£€æŸ¥æ˜¯å¦è¯·æ±‚åˆ†æå·¥ä½œåŒºæ–‡ä»¶
      const fileMatch = message.content.match(/åˆ†æ(?:æ–‡ä»¶)?\s*[`"']?([^\s"'`]+?)[`"']?$/);
      if (fileMatch) {
        return await this.analyzeFile(fileMatch[1], context);
      }

      // é»˜è®¤è¿”å›ä½¿ç”¨è¯´æ˜
      return {
        content: this.getUsageHelp(),
        agentId: this.id,
      };

    } catch (error) {
      logger.error(`[DataAnalysisAgent] å¤„ç†å¤±è´¥: ${error}`);
      return {
        content: `åˆ†æå¤±è´¥: ${error instanceof Error ? error.message : String(error)}`,
        agentId: this.id,
      };
    }
  }

  /**
   * åˆ†æé™„ä»¶æ–‡ä»¶
   */
  private async analyzeAttachment(
    message: AgentMessage,
    context: AgentContext
  ): Promise<AgentResponse> {
    const attachment = message.attachments![0];
    const filePath = attachment.path;

    // æ£€æŸ¥æ–‡ä»¶å¤§å°
    const stats = await fs.stat(filePath);
    if (stats.size > this.maxFileSize) {
      return {
        content: `æ–‡ä»¶è¿‡å¤§ (${(stats.size / 1024 / 1024).toFixed(2)}MB)ï¼Œæœ€å¤§æ”¯æŒ ${this.maxFileSize / 1024 / 1024}MB`,
        agentId: this.id,
      };
    }

    const ext = path.extname(filePath).toLowerCase();

    switch (ext) {
      case '.json':
        return await this.analyzeJsonFile(filePath);
      case '.csv':
        return await this.analyzeCsvFile(filePath);
      case '.txt':
      case '.md':
        return await this.analyzeTextFile(filePath);
      default:
        return {
          content: `ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: ${ext}`,
          agentId: this.id,
        };
    }
  }

  /**
   * åˆ†ææŒ‡å®šæ–‡ä»¶
   */
  private async analyzeFile(
    fileName: string,
    context: AgentContext
  ): Promise<AgentResponse> {
    const filePath = path.join(context.workspacePath, fileName);

    try {
      await fs.access(filePath);
    } catch {
      return {
        content: `æ–‡ä»¶ä¸å­˜åœ¨: ${fileName}`,
        agentId: this.id,
      };
    }

    const ext = path.extname(fileName).toLowerCase();

    switch (ext) {
      case '.json':
        return await this.analyzeJsonFile(filePath);
      case '.csv':
        return await this.analyzeCsvFile(filePath);
      default:
        return await this.analyzeTextFile(filePath);
    }
  }

  /**
   * åˆ†æ JSON æ–‡ä»¶
   */
  private async analyzeJsonFile(filePath: string): Promise<AgentResponse> {
    const content = await fs.readFile(filePath, 'utf-8');
    const data = JSON.parse(content);

    const stats = this.analyzeJsonData(data);

    let output = `ğŸ“Š JSON æ–‡ä»¶åˆ†æ\n\n`;
    output += `**æ–‡ä»¶**: ${path.basename(filePath)}\n`;
    output += `**å¤§å°**: ${(content.length / 1024).toFixed(2)} KB\n\n`;
    output += `**ç»“æ„åˆ†æ**:\n`;
    output += `- æ•°æ®ç±»å‹: ${Array.isArray(data) ? 'æ•°ç»„' : typeof data}\n`;
    output += `- ${stats.summary}\n`;

    if (stats.fields && stats.fields.length > 0) {
      output += `\n**å­—æ®µåˆ—è¡¨**:\n`;
      stats.fields.forEach(field => {
        output += `- \`${field.name}\` (${field.type})\n`;
      });
    }

    return { content: output, agentId: this.id };
  }

  /**
   * åˆ†æ JSON æ•°æ®ç»“æ„
   */
  private analyzeJsonData(data: unknown, depth = 0): {
    summary: string;
    fields?: Array<{ name: string; type: string }>;
  } {
    if (Array.isArray(data)) {
      if (data.length === 0) {
        return { summary: 'ç©ºæ•°ç»„' };
      }
      const firstItem = data[0];
      if (typeof firstItem === 'object' && firstItem !== null) {
        const fields = Object.keys(firstItem).map(key => ({
          name: key,
          type: typeof firstItem[key as keyof typeof firstItem],
        }));
        return {
          summary: `${data.length} ä¸ªå…ƒç´ çš„æ•°ç»„`,
          fields,
        };
      }
      return { summary: `${data.length} ä¸ªå…ƒç´ çš„ ${typeof firstItem} æ•°ç»„` };
    }

    if (typeof data === 'object' && data !== null) {
      const keys = Object.keys(data);
      const fields = keys.map(key => ({
        name: key,
        type: typeof data[key as keyof typeof data],
      }));
      return {
        summary: `${keys.length} ä¸ªå­—æ®µçš„å¯¹è±¡`,
        fields,
      };
    }

    return { summary: `åŸºæœ¬ç±»å‹: ${typeof data}` };
  }

  /**
   * åˆ†æ CSV æ–‡ä»¶
   */
  private async analyzeCsvFile(filePath: string): Promise<AgentResponse> {
    const content = await fs.readFile(filePath, 'utf-8');
    const lines = content.split('\n').filter(line => line.trim());

    if (lines.length === 0) {
      return {
        content: `CSV æ–‡ä»¶ä¸ºç©º`,
        agentId: this.id,
      };
    }

    const headers = lines[0].split(',').map(h => h.trim());
    const rowCount = lines.length - 1; // å‡å»è¡¨å¤´

    let output = `ğŸ“Š CSV æ–‡ä»¶åˆ†æ\n\n`;
    output += `**æ–‡ä»¶**: ${path.basename(filePath)}\n`;
    output += `**å¤§å°**: ${(content.length / 1024).toFixed(2)} KB\n\n`;
    output += `**ç»“æ„åˆ†æ**:\n`;
    output += `- æ€»è¡Œæ•°: ${rowCount}\n`;
    output += `- åˆ—æ•°: ${headers.length}\n\n`;
    output += `**åˆ—å**:\n`;
    headers.forEach((h, i) => {
      output += `${i + 1}. \`${h}\`\n`;
    });

    return { content: output, agentId: this.id };
  }

  /**
   * åˆ†ææ–‡æœ¬æ–‡ä»¶
   */
  private async analyzeTextFile(filePath: string): Promise<AgentResponse> {
    const content = await fs.readFile(filePath, 'utf-8');
    const lines = content.split('\n');
    const words = content.split(/\s+/).filter(w => w.trim());
    const chars = content.length;

    let output = `ğŸ“„ æ–‡æœ¬æ–‡ä»¶åˆ†æ\n\n`;
    output += `**æ–‡ä»¶**: ${path.basename(filePath)}\n`;
    output += `**å¤§å°**: ${(chars / 1024).toFixed(2)} KB\n\n`;
    output += `**ç»Ÿè®¡ä¿¡æ¯**:\n`;
    output += `- å­—ç¬¦æ•°: ${chars}\n`;
    output += `- å•è¯æ•°: ${words.length}\n`;
    output += `- è¡Œæ•°: ${lines.length}\n`;
    output += `- å¹³å‡è¡Œé•¿åº¦: ${(chars / lines.length).toFixed(1)} å­—ç¬¦\n`;

    return { content: output, agentId: this.id };
  }

  /**
   * è·å–ä½¿ç”¨å¸®åŠ©
   */
  private getUsageHelp(): string {
    return `ğŸ“Š **Data Analysis Agent ä½¿ç”¨è¯´æ˜**

æˆ‘å¯ä»¥å¸®ä½ åˆ†æä»¥ä¸‹ç±»å‹çš„æ–‡ä»¶ï¼š

**æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**:
- .json - JSON æ•°æ®æ–‡ä»¶
- .csv - CSV è¡¨æ ¼æ–‡ä»¶
- .txt - çº¯æ–‡æœ¬æ–‡ä»¶
- .md - Markdown æ–‡æ¡£

**ä½¿ç”¨æ–¹å¼**:
1. å‘é€æ–‡ä»¶ç»™æˆ‘ï¼ˆQQ é™„ä»¶ï¼‰
2. è¯´ "åˆ†æ xxx.json" åˆ†æå·¥ä½œåŒºæ–‡ä»¶

**åˆ†æåŠŸèƒ½**:
- æ–‡ä»¶ç»“æ„åˆ†æ
- æ•°æ®ç»Ÿè®¡ï¼ˆè¡Œæ•°ã€åˆ—æ•°ã€å­—æ®µç±»å‹ï¼‰
- å†…å®¹æ‘˜è¦`;
  }

  /**
   * åˆå§‹åŒ–
   */
  async initialize(): Promise<void> {
    logger.info('[DataAnalysisAgent] å·²åˆå§‹åŒ–');
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async cleanup(): Promise<void> {
    logger.info('[DataAnalysisAgent] å·²æ¸…ç†èµ„æº');
  }
}

export default DataAnalysisAgent;
