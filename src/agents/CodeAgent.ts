/**
 * Code Agent - ç®€å•ä»£ç ä»»åŠ¡å¤„ç†
 *
 * æ”¯æŒä½¿ç”¨ Anthropic API æˆ– GLM API (Coding Plan)
 * å¤„ç†ç®€å•ä»£ç ç¼–å†™å’Œåˆ†æä»»åŠ¡ï¼Œé¿å…è°ƒç”¨é‡é‡çº§çš„ Claude Code CLI
 */

import Anthropic from '@anthropic-ai/sdk';
import { logger } from '../utils/logger.js';
import type {
  IAgent,
  AgentConfig,
  AgentMessage,
  AgentContext,
  AgentResponse,
} from './base/Agent.js';
import { AgentCapability } from './base/Agent.js';

/**
 * Code Agent é…ç½®é€‰é¡¹
 */
export interface CodeAgentOptions {
  /** Anthropic API Key (å¯é€‰) */
  apiKey?: string;
  /** GLM API Key (å¯é€‰ï¼ŒCoding Plan API) */
  glmApiKey?: string;
  /** GLM API Base URL (å¯é€‰) */
  glmBaseUrl?: string;
  /** ä½¿ç”¨çš„æ¨¡å‹ */
  model?: string;
  /** æœ€å¤§ tokens */
  maxTokens?: number;
}

/**
 * Code Agent - å¤„ç†ç®€å•ä»£ç ä»»åŠ¡
 */
export class CodeAgent implements IAgent {
  readonly id = 'code';
  readonly name = 'Code Agent';
  readonly description = 'å¤„ç†ç®€å•ä»£ç ç¼–å†™ã€åˆ†æå’Œè°ƒè¯•ä»»åŠ¡';
  readonly capabilities: AgentCapability[] = [
    AgentCapability.Code,
    AgentCapability.Analyze,
  ];
  readonly config: AgentConfig = {
    enabled: true,
    priority: 10,
    timeout: 60000,
  };

  private client?: Anthropic;
  private glmApiKey?: string;
  private glmBaseUrl?: string;
  private model: string;
  private maxTokens: number;
  private useGLM: boolean;

  // ä»£ç ç›¸å…³å…³é”®è¯
  private readonly codeKeywords = [
    // ä¸­æ–‡
    'ä»£ç ', 'å†™', 'å‡½æ•°', 'ç±»', 'å®ç°', 'bug', 'è°ƒè¯•', 'ç®—æ³•', 'æ•°æ®ç»“æ„',
    'è§£é‡Šä»£ç ', 'åˆ†æä»£ç ', 'é‡æ„', 'ä¼˜åŒ–ä»£ç ',
    // è‹±æ–‡
    'code', 'write', 'function', 'class', 'implement', 'debug', 'algorithm',
    'data structure', 'explain code', 'analyze code', 'refactor', 'optimize code',
    // ç¼–ç¨‹è¯­è¨€
    'javascript', 'typescript', 'python', 'java', 'c++', 'go', 'rust', 'php',
    'html', 'css', 'sql', 'bash', 'shell',
  ];

  constructor(options: CodeAgentOptions) {
    // ä¼˜å…ˆä½¿ç”¨ Anthropic APIï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ GLM API
    if (options.apiKey) {
      this.client = new Anthropic({
        apiKey: options.apiKey,
      });
      this.model = options.model || 'claude-3-5-sonnet-20241022';
      this.useGLM = false;
      logger.info(`[CodeAgent] åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: ${this.model}, API: Anthropic)`);
    } else if (options.glmApiKey) {
      this.glmApiKey = options.glmApiKey;
      this.glmBaseUrl = options.glmBaseUrl || 'https://api.z.ai/api/coding/paas/v4/';
      this.model = options.model || 'glm-4.7';
      this.maxTokens = options.maxTokens || 8192;
      this.useGLM = true;
      logger.info(`[CodeAgent] åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: ${this.model}, API: GLM Coding Plan)`);
    } else {
      throw new Error('Code Agent åˆå§‹åŒ–å¤±è´¥: éœ€è¦æä¾› apiKey æˆ– glmApiKey');
    }
    this.maxTokens = options.maxTokens || 4096;
  }

  /**
   * æ£€æŸ¥æ˜¯å¦èƒ½å¤„ç†è¯¥ä»»åŠ¡
   */
  canHandle(message: AgentMessage): number {
    const content = message.content.toLowerCase();

    // æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç ç‰‡æ®µ
    const hasCodeSnippet = /```[\s\S]*```|`[^`\n]+`/.test(message.content);
    if (hasCodeSnippet) {
      return 0.95;
    }

    // å…³é”®è¯åŒ¹é…
    const hitCount = this.codeKeywords.filter(kw => content.includes(kw)).length;
    const score = Math.min(hitCount * 0.15, 0.85);

    return score;
  }

  /**
   * å¤„ç†æ¶ˆæ¯
   */
  async process(
    message: AgentMessage,
    context: AgentContext
  ): Promise<AgentResponse> {
    const startTime = Date.now();

    try {
      logger.info(`[CodeAgent] å¤„ç†æ¶ˆæ¯: ${message.content.substring(0, 50)}...`);

      const systemPrompt = this.buildSystemPrompt(context);
      const userPrompt = this.buildUserPrompt(message);

      let text: string;

      if (this.useGLM) {
        // ä½¿ç”¨ GLM API (Coding Plan)
        text = await this.callGLMAPI(systemPrompt, userPrompt);
      } else {
        // ä½¿ç”¨ Anthropic API
        const response = await this.client!.messages.create({
          model: this.model,
          max_tokens: this.maxTokens,
          system: systemPrompt,
          messages: [{
            role: 'user',
            content: userPrompt,
          }],
        });

        const contentBlock = response.content[0];
        text = contentBlock.type === 'text' ? contentBlock.text : '';
      }

      const elapsed = Date.now() - startTime;
      logger.info(`[CodeAgent] å¤„ç†å®Œæˆï¼Œè€—æ—¶: ${elapsed}ms`);

      return {
        content: `ğŸ¤– [Code Agent]\n\n${text}`,
        agentId: this.id,
      };

    } catch (error) {
      logger.error(`[CodeAgent] å¤„ç†å¤±è´¥: ${error}`);
      return {
        content: `âŒ [Code Agent] å¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : String(error)}`,
        agentId: this.id,
      };
    }
  }

  /**
   * è°ƒç”¨ GLM API (Coding Plan æ ¼å¼)
   */
  private async callGLMAPI(systemPrompt: string, userPrompt: string): Promise<string> {
    const response = await fetch(`${this.glmBaseUrl}chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.glmApiKey}`,
      },
      body: JSON.stringify({
        model: this.model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        max_tokens: this.maxTokens,
        temperature: 0.7,  // OpenClaw å…¼å®¹
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`GLM API error ${response.status}: ${errorText}`);
    }

    const data = await response.json();
    return data.choices[0]?.message?.content || '';
  }

  /**
   * æ„å»ºç³»ç»Ÿæç¤ºè¯
   */
  private buildSystemPrompt(context: AgentContext): string {
    return `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œæ“…é•¿å¤„ç†ç®€å•ä»£ç ä»»åŠ¡ã€‚

ä½ çš„èŒè´£ï¼š
1. ç¼–å†™ç®€æ´ã€é«˜æ•ˆçš„ä»£ç ç‰‡æ®µ
2. è§£é‡Šä»£ç é€»è¾‘å’Œå·¥ä½œåŸç†
3. åˆ†æå’Œè°ƒè¯•ä»£ç é—®é¢˜
4. æä¾›ä»£ç ä¼˜åŒ–å»ºè®®

æ³¨æ„äº‹é¡¹ï¼š
- ä¿æŒå›ç­”ç®€æ´æ˜äº†
- ä»£ç è¦æœ‰æ³¨é‡Šè¯´æ˜
- å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œå»ºè®®ç”¨æˆ·ä½¿ç”¨å®Œæ•´çš„ Claude Code CLI
- å½“å‰å·¥ä½œç›®å½•: ${context.workspacePath}

è¯·ç›´æ¥ç»™å‡ºä»£ç æˆ–åˆ†æç»“æœï¼Œä¸éœ€è¦è¿‡å¤šçš„å¼€åœºç™½ã€‚`;
  }

  /**
   * æ„å»ºç”¨æˆ·æç¤ºè¯
   */
  private buildUserPrompt(message: AgentMessage): string {
    let prompt = message.content;

    // å¦‚æœæœ‰é™„ä»¶ï¼Œæ·»åŠ é™„ä»¶ä¿¡æ¯
    if (message.attachments && message.attachments.length > 0) {
      const attachmentInfo = message.attachments
        .map(a => `- ${a.type}: ${a.path}`)
        .join('\n');
      prompt += `\n\né™„ä»¶:\n${attachmentInfo}`;
    }

    return prompt;
  }

  /**
   * åˆå§‹åŒ–
   */
  async initialize(): Promise<void> {
    // æ ¹æ®ä½¿ç”¨çš„ API ç±»å‹è¿›è¡ŒéªŒè¯
    try {
      if (this.useGLM) {
        // ä½¿ç”¨ GLM API éªŒè¯
        const response = await fetch(`${this.glmBaseUrl}chat/completions`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.glmApiKey}`,
          },
          body: JSON.stringify({
            model: this.model,
            messages: [{ role: 'user', content: 'Hi' }],
            max_tokens: 10,
          }),
        });

        if (!response.ok) {
          throw new Error(`GLM API error ${response.status}`);
        }
        logger.info('[CodeAgent] API è¿æ¥éªŒè¯æˆåŠŸ (GLM)');
      } else {
        // ä½¿ç”¨ Anthropic API éªŒè¯
        await this.client!.messages.create({
          model: this.model,
          max_tokens: 10,
          messages: [{ role: 'user', content: 'Hi' }],
        });
        logger.info('[CodeAgent] API è¿æ¥éªŒè¯æˆåŠŸ (Anthropic)');
      }
    } catch (error) {
      logger.warn(`[CodeAgent] API è¿æ¥éªŒè¯å¤±è´¥: ${error}`);
      throw new Error(`Code Agent åˆå§‹åŒ–å¤±è´¥: ${error}`);
    }
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async cleanup(): Promise<void> {
    // Anthropic SDK ä¸éœ€è¦æ˜¾å¼æ¸…ç†
    logger.info('[CodeAgent] å·²æ¸…ç†èµ„æº');
  }
}
